[
  {
    "objectID": "chapter_8.html#summary",
    "href": "chapter_8.html#summary",
    "title": "9  SAR",
    "section": "9.1 Summary",
    "text": "9.1 Summary\nThis is the last week for the learning dairy, and we wrapped up the module with Synthetic Aperture Radar (SAR). This was a shift from the passive sensors, like optical sensors, to active sensors unlike in the previous sessions. I will focus on SAR for this week and try to understand board scope of it as is still new to me.\n\n9.1.1 SAR Background\nAs an active sensor, it produces its own energy in a form of microwave pulses to and records the reflected pulses (called backscatter) to generate images. The use of microwave signals in SAR allows it to penetrate thin objects easily. This is particularly relevant in remote sensing as it reduces the chances of interference by clouds in the data. Also, the SAR not dependant on sunlight thus, can operate day and night.\n\n\n9.1.2 How SAR Works\nSAR sensor analyses the backscatter signals to create the images. The strength and phase of these backscatter signals provide information about surface texture, roughness, and material composition. The key advantage is that SAR synthesizes a large virtual aperture by moving along its flight path, which allows it to achieve high-resolution imaging.\n\n\n9.1.3 Data from SAR\nSAR data is primarily in the form of backscatter intensity and texture information, which is highly dependent on resolution.\n\nLow-resolution SAR produces a coarse texture, suitable for large-scale land cover mapping.\nHigh-resolution SAR reveals fine surface details, useful for urban infrastructure and detailed terrain analysis.\n\nResolution is also influenced by the antenna length—a longer antenna results in better resolution hence the essence of the Synthetic Aperture.\n\n\n9.1.4 Key Applications of SAR\nThere are two major techniques in geospatial applications: - InSAR (Interferometric SAR): Used for generating Digital Elevation Models (DEMs) by converting phase differences into relative height measurements. - DInSAR (Differential InSAR): Detects ground movement (uplift or subsidence) by comparing SAR images over time, with topographic influences removed using a DEM.\n\n\n9.1.5 Limitations and possible future developments.\nOne major challenge with SAR is the complex preprocessing required to make the data usable. Steps like orbit correction, radiometric calibration, de-bursting, multilooking, speckle filtering, and terrain correction are tedious but necessary. Based on my experience with data wrangling in CASA005, preprocessing often leads to some data loss, which is a concern for analysis accuracy. In the future, improved automated SAR processing pipelines could help streamline this workflow and make SAR data more accessible for everyday users."
  },
  {
    "objectID": "chapter_8.html#application",
    "href": "chapter_8.html#application",
    "title": "9  SAR",
    "section": "9.2 Application",
    "text": "9.2 Application\nThis week, I wanted to look at a more hands-on use of SAR — detecting and tracking ships on water.\nThe first study by Ouchi (2016) explores how SAR is used for ship detection and classification. everal methods were tested, but CFAR (Constant False Alarm Rate) stood out for its simplicity and effectiveness. CFAR is a statistical method that sets a threshold based on background noise, allowing it to detect ships even in cluttered environments.\nThe author also discussed different SAR modes, which affect how much area is captured and at what resolution:\n\nStripmap Mode: High resolution, but narrow swath.\nScanSAR Mode: Lower resolution, but covers a wider area.\nSingle-Polarization SAR: Sends and receives in one direction (e.g., HH or VV).\nFully Polarimetric SAR: Uses multiple polarizations (HH, HV, VH, VV), giving richer data for separating ships from sea clutter.\n\n\n\n\nFig. 1 HH-, HV-, and VV-polarizations (Ouchi, 2016)\n\n\nHV provides the strongest ship-to-background contrast.\nThe second study by Yasir et al. (2024) demonstrated ship detection using Gaofen-3 SAR imagery (1m resolution) with a YOLOv8 model for detection and a C-BIOU tracker for following ships over time.\n\n\n\nFig. 2 Workflow of the ship tracking model (Yasir et al., 2024)\n\n\nThe second study by Yasir et al. (2024) demonstrated ship detection using Gaofen-3 SAR imagery (1m resolution) with a YOLOv8 model for detection and a C-BIOU tracker for following ships over time.\nThe whole model is built around SAR data, probably because SAR can see through clouds and works both day and night, which is a big deal at sea. One downside is they used Gaofen-3, and that data isn’t easy to get—it’s not public, so unless you have access, it might be hard to try the same thing. Still, the study really shows how powerful SAR can be for spotting and tracking ships, even in tricky conditions.\n\n9.2.1 Key insights\nBoth papers show SAR is highly effective for ship detection. However, there’s always a trade-off between resolution, polarization, and coverage. Choosing the right SAR setup depends on the goal—whether it’s wide surveillance or detailed tracking in coastal zones."
  },
  {
    "objectID": "chapter_8.html#reflection",
    "href": "chapter_8.html#reflection",
    "title": "9  SAR",
    "section": "9.3 Reflection",
    "text": "9.3 Reflection\nThis is the last week of the learning diary. I chose vessel detection as my focus because many major cities are built along the coast, and with the rise in personal boat ownership, there’s a growing need for better monitoring of maritime activity—from small crafts to large vessels.\nWhile going through the SAR-based detection studies, I found myself wondering: if SAR mainly detects surface texture, how does it spot ships during rough sea or stormy conditions? Does the radar band slightly penetrate the water or is the ship’s location just inferred from a prediction model using previous data?\nFrom the papers, it seems SAR can still detect ships directly—even under challenging conditions—and weather wasn’t really mentioned as a limitation. This suggests that the choice of wavelength or band plays a big role in how well SAR handles stormy seas. It also shows how deep learning paired with SAR is helping reduce those limitations, making ship detection more accurate and real-time.\nTo wrap it up, this week showed me that SAR isn’t just useful but its impact is great when applied well. And in a world where coastal cities are expanding fast, having tools like this could make a real difference in monitoring, security, and sustainability at sea."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Preface",
    "section": "",
    "text": "This is a diary showing my progress, understanding, and interests in remote sensing. My background in civil engineering, green/sustainable development (as an EDGE expert), and sound engineering might influence how I reflect on the content and what stands out to me.\nAs a Ghanaian, I’m also interested in how remote sensing methods and sensors apply across both developing and developed countries. I’ll likely reflect on how universal or adaptable these approaches really are.\nWhere possible, I will also consider some economic or financial implications of some methods or strategies discussed each week—especially in terms of how feasible they are in different contexts.\nOverall, my reflections will focus on remote sensing and its value for urban development, while trying to keep a neutral and critical perspective on its benefits and limitations."
  },
  {
    "objectID": "chapter_1.html#introduction",
    "href": "chapter_1.html#introduction",
    "title": "2  Introduction to Remote Sensing & Satellite Data",
    "section": "2.1 Introduction",
    "text": "2.1 Introduction\nI currently understand remote sensing as the process of gathering information about the Earth’s surface without direct contact. This is done through passive sensors (like satellite imagery) and active sensors (like LiDAR and RADAR). Passive sensors detect reflected sunlight, while active ones send out pulses (e.g., lasers) and measure what bounces back. Both rely on electromagnetic waves. Remote sensing is often combined with GIS to analyse landscapes, land cover, urban areas, and environmental change. The combination of these techniques, and the data they produce, enables environmental monitoring, resource management, and biodiversity conservation at different spatial scales. Figure 1 summarizes it all.\n\n\n\nFig.1 Overview of Remote Sensing (Kerry et al., 2022)\n\n\nWhat caught my attention this week was the role of satellites—these suspended systems orbiting Earth. Remote sensing and satellites go hand-in-hand, but I hadn’t really considered the different types before. There are:\n\nGeostationary satellites – stationary, mainly used for weather, telecoms, and large-scale monitoring.\nLow Earth Orbit (LEO) satellites – used for high-resolution imaging, orbiting 160–2,000 km above Earth.\nSun-synchronous (polar) satellites – orbit Earth in sync with the sun, useful for consistent scientific observations.\n\nThe sun-synchronous satellites, especially Sentinel-2 and Landsat-8, stood out to me because they’re both widely used in environmental monitoring. Here’s a brief comparison:\n\n\n\nFeature\nLandsat-8\nSentinel-2\n\n\n\n\nResolution\n30m\n10-60m\n\n\nRevisit Time\n16days\n5days\n\n\nBands\n11 bands\n13 bands\n\n\n\nA term that I think will keep coming up is bands. Bands are like filters for specific wavelengths of light. Each band captures data differently, and depending on which are available, a satellite may be better suited for certain tasks. For instance, near-infrared is good for vegetation monitoring, while shortwave infrared helps with detecting soil moisture. Looking at the image here (figure 2),\n\n\n\nFig. 2 Comparison of Landsat 7 and 8 bands with Sentinel-2 (Earth Resources Observation and Science (EROS) Center, 2019)\n\n\nI noticed that while both satellites share some bands, they also have unique ones. For example, Landsat-8 includes a Thermal Infrared Sensor (TIRS) which Sentinel-2 lacks—this means Landsat can provide thermal data like land surface temperature (LST), which is valuable in urban heat studies.\nUnderstanding bands will be key in selecting the right satellite for different types of studies. It’s already helping me see how technical features link to practical applications."
  },
  {
    "objectID": "chapter_1.html#application",
    "href": "chapter_1.html#application",
    "title": "2  Introduction to Remote Sensing & Satellite Data",
    "section": "2.2 Application",
    "text": "2.2 Application\nFor this section, I wanted to use what I learned in the summary to figure out which satellite is more suitable for land cover classification.\nA study by Ahady, A.B. and Kaplan, G. compared Landsat-8 and Sentinel-2 data over the city of Kabul, focused on classification accuracy across four land cover types: water, cropland, urban, and bare land. This was done using Support Vector Machine (SVM) classifier.\nKey insights\n\nLandsat-8 had an overall classification accuracy 85.04%.\nSentinel-2 had a classification accuracy of 94.26%.\n\nLet’s look at the outputs:\n\n\n\nFig. 3 Landsat-8’s imagery of Kabul city generated on Apr-June 2020 (Ahady and Kaplan, 2022)\n\n\n\n\n\nFig. 4 Sentinel-2 imagery of Kabul city generated on Apr-June 2020 (Ahady and Kaplan, 2022)\n\n\nFrom the images, it’s clear that Sentinel-2 (Figure 4) shows finer detail compared to Landsat-8 (Figure 3). One major reason could be the spatial resolution—Sentinel-2 has higher resolution, which allows it to define features more clearly, especially in urban and mixed-use areas. That likely contributes to its higher classification accuracy.\nAnother factor could be the revisit time. Sentinel-2 revisits every 5 days, while Landsat-8 takes 16 days. That means more cloud-free images are available from Sentinel-2 within the same time frame, which improves the chance of capturing clearer, more usable data.\nLastly, the spectral bands might also influence classification. As I noted earlier, bands are like filters that let satellites “see” certain land characteristics. The study used surface reflectance bands, and the near-infrared (NIR) band was especially important. For Landsat-8, that’s Band 5, and for Sentinel-2, it’s Band 8. NIR is key for separating vegetation from built-up areas, which makes it critical in land classification.\nThat said, I don’t think the study’s results mean Sentinel-2 is always better. One limitation might be the classification model used. Also, I wonder whether both satellite images fully covered the same tile or whether mosaicking was done. That could affect consistency and reduce the robustness of the comparison.\nSo, while Sentinel-2 performed better in this study, context matters. Landsat might still be more suitable in other scenarios—especially where thermal data (like LST) or historical depth is needed."
  },
  {
    "objectID": "chapter_1.html#reflection",
    "href": "chapter_1.html#reflection",
    "title": "2  Introduction to Remote Sensing & Satellite Data",
    "section": "2.3 Reflection",
    "text": "2.3 Reflection\nIt’s the first week of the term, and to be honest, it’s been a bit of a slow start. I’m still figuring out what I will take away from this course. Probable by Week 10 I will have a clearer answer. For now, I’ve got a much better grasp of the basics of remote sensing: types of sensors, surface reflectance, atmospheric interference, and how satellites and bands come into play. It’s a lot to take in, but I’m starting to connect the dots.\nSomething I’ve been thinking about is whether we can combine Landsat and Sentinel data to make better sense of climate change. Landsat has the long archive, and Sentinel gives more frequent and detailed images. Putting them together could help us spot trends over time—like, are we really seeing lasting climate change, or are we just in a long seasonal cycle that feels different but has happened before? This is a big question, especially in Europe where climate change is felt. Like snow not falling in London like how it did in previous years. Having both satellites working together might help reveal whether we’re dealing with natural variation or a real shift.\nRemote sensing, I believe will have more impact in developing countries. Ghana as a developing country could benefit from as it can monitor the land use, deforestation, and pollution. This could help in planning and decision-making. For instance, the Sentinel-5P satellite can monitor pollution levels in the atmosphere. This could be useful in Accra, where pollution levels are high.\nAlso, about SNAP—yeah, that practical was rough. Clunky interface, laggy tools, not fun. But I did get a feel for the kind of hands-on work remote sensing really involves."
  },
  {
    "objectID": "chapter_1.html#references",
    "href": "chapter_1.html#references",
    "title": "2  Introduction to Remote Sensing & Satellite Data",
    "section": "2.4 References",
    "text": "2.4 References\nEarth Resources Observation and Science (EROS) Center, 2024. Remote Sensing Satellites. URL https://satpalda.com/remote-sensing-satellites/, https://satpalda.com/remote-sensing-satellites/ (accessed 3.28.25).\nAhady, A.B., Kaplan, G., 2022. Classification comparison of Landsat-8 and Sentinel-2 data in Google Earth Engine, study case of the city of Kabul. Int. J. Eng. Geosci. 7, 24–31. https://doi.org/10.26833/ijeg.860077\nEarth Resources Observation and Science (EROS) Center, 2019. Comparison of Landsat 7 and 8 bands with Sentinel-2 | U.S. Geological Survey [WWW Document]. URL https://www.usgs.gov/media/images/comparison-landsat-7-and-8-bands-sentinel-2 (accessed 3.28.25).\nKerry, R.G., Montalbo, F.J.P., Das, R., Patra, S., Mahapatra, G.P., Maurya, G.K., Nayak, V., Jena, A.B., Ukhurebor, K.E., Jena, R.C., Gouda, S., Majhi, S., Rout, J.R., 2022. An overview of remote monitoring methods in biodiversity conservation. Environ. Sci. Pollut. Res. 29, 80179–80221. https://doi.org/10.1007/s11356-022-23242-y"
  },
  {
    "objectID": "chapter_2.html",
    "href": "chapter_2.html",
    "title": "3  Xaringan presentation",
    "section": "",
    "text": "This is a link for a xaringan presentation: MODIS\nThe presentations covers an overview, applications and some reflections on the MODIS sensor."
  },
  {
    "objectID": "chapter_3.html#summary",
    "href": "chapter_3.html#summary",
    "title": "4  Remote sensing data",
    "section": "4.1 Summary",
    "text": "4.1 Summary\nThis week’s session was mainly on image corrections and enhancement techniques. These are akey steps in preparing satellite imagery for analysis. Raw satellite data often has issues due to the sensor’s position, the Earth’s surface, or the atmosphere. Here is a summary of some of the issues and how they’re typically corrected:\n\n\n\n\n\n\n\n\nError\nEffect\nCorrection\n\n\n\n\nGeometric Distortion\nFeatures misaligned or warped\nGeoreferencing / Orthorectification\n\n\nRadiometric Distortion\nPixel brightness doesn’t match real reflectance\nRadiometric Calibration\n\n\nAtmospheric Effects\nHaze/clouds distort pixel values\nAtmospheric Correction (TOA → BOA)\n\n\nSeamline Artifacts\nVisible lines between image tiles\nSeamline Editing / Feathering\n\n\nColour Mismatch\nInconsistent brightness/tones between images\nColour Balancing / Normalisation\n\n\n\nThese corrections improve image consistency, making it possible for multi-temporal or multi-sensor analysis. This is particularly useful in urban studies where you might have to use different data types to achieve a task.\nWe also touched on important terms on the corrections workflow:\nFor Corrections & Calibration\n\n\n\n\n\n\n\nTerm\nWhat It Means\n\n\n\n\nDN (Digital Number)\nRaw pixel value straight from the satellite sensor\n\n\nRadiance\nThe actual energy (brightness) measured by the sensor — calculated from DN\n\n\nReflectance\nHow much sunlight the surface reflects — helps identify materials\n\n\nTOA Reflectance\nWhat the satellite “sees” before atmospheric correction\n\n\nBOA Reflectance\nReflectance after correcting for atmospheric effects — closer to surface truth\n\n\nRadiometric Calibration\nAdjusting DN values to reflect real-world energy/brightness\n\n\n\nThis week, I focused on TOA vs BOA reflectance. Many satellite products (like Sentinel-2 Level-1C) come in TOA form, which includes interference from the atmosphere. But for detailed analysis—like vegetation health, land cover classification, or urban change—BOA reflectance is essential. It gives a clearer, more accurate picture of what’s actually happening on the ground by removing distortions from haze, clouds, or sunlight angles. Without this correction, analyses can misrepresent real surface conditions, leading to flawed decisions or models."
  },
  {
    "objectID": "chapter_3.html#application",
    "href": "chapter_3.html#application",
    "title": "4  Remote sensing data",
    "section": "4.2 Application",
    "text": "4.2 Application\nFor this week, I will look at papers exploring the relationship between TOA and BOA reflectance.\n\n4.2.1 NDVI (BOA) vs NDVI (TOA) in Sentinel-2 Data\nThe first article is by Lauri(2019) who compares NDVI values derived from TOA and BOA reflectance using Sentinel-2 data. Figure 1 show the Sentinel-2 image of Tampere used in the study.\n\n\n\nFig. 1 Sentinel-2 scene from Tampere (Lauri, 2019)\n\n\nThe finding of the study showed that NDVI calculated from BOA reflectance is consistently higher and more reliable than from TOA, as shown in figure 2. This makes sense because TOA includes atmospheric interference like haze and scattering, which can reduce apparent greenness.\n\n\n\nFig. 2 NDVI(BOA) vs. NDVI(TOA) (Lauri, 2019)\n\n\nSo, for something like crop monitoring or tracking urban vegetation, relying on TOA reflectance could understate actual plant health, while BOA gives a sincerer picture. This goes to show how the atmospheric correction can impact the findings of the data.\n\n\n4.2.2 Testing Atmospheric Correction Methods\nThe second paper by Nazeer et al. evaluated how well different correction methods convert TOA to BOA reflectance for PlanetScope, Sentinel-2, and Landsat-8 imagery. They proposed a new model called SREM, designed to work even without complex atmospheric data like AOD or ozone levels.\nThey validated their results using reference surface reflectance data (BOA) from a radiative transfer model (6SV) and AERONET station data. Their SREM method came out quite accurate across all three sensors and different land types as shown in figure 3.\n\n\n\nFig. 3 Findings of comparisons across sensors\n\n\nThis is especially useful for studies in places without ground monitoring stations (like Ghana), where full atmospheric inputs aren’t available. It shows you can still produce BOA-level outputs from TOA data using clever modelling.\n\n\n4.2.3 Insights\nBoth articles made it clear that the shift from TOA to BOA isn’t optional if you want reliable, detailed land analysis. Even for something basic like NDVI, skipping that step can skew your results. And with better correction models like SREM, BOA is becoming more accessible—even in data-scarce areas."
  },
  {
    "objectID": "chapter_3.html#reflection",
    "href": "chapter_3.html#reflection",
    "title": "4  Remote sensing data",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection\nThis week’s lecture was packed with information and technical terms in remote sensing. Honestly, it was a bit challenging trying to fully grasp all the terminologies used in the lecture.\nI chose to focus on TOA and BOA reflectance because they connect to one of the trickiest issues in remote sensing: clouds. Just like when you’re in a plane and can see both clouds and the ground, satellites face the same challenge. As sunlight travels back to the satellite sensor, it gets partially blocked or scattered by particles in the atmosphere, like aerosols.\nThis is important because many satellite datasets are provided in TOA reflectance, which includes this interference. To get accurate information about the Earth’s surface, we need to correct it to BOA reflectance, which removes most of the atmospheric effects.\nSome questions that came to mind were:\nWhen exactly does the scattering happen?\nIs it when the sunlight reflects off the Earth and travels back through the atmosphere to the sensor?\nOr does it scatter on the way down to the surface too?\nI think the first is more likely, but I’m not entirely sure. It’s something I’d definitely like to explore more, especially how this impacts vegetation indices and urban analysis.\nAnother interesting thought is how this could be flipped—using the difference between TOA and BOA not just to improve surface analysis, but to study the atmosphere itself. For example, the gap between the two might help scientists track air pollution, smoke, or dust events, especially in areas without ground sensors. So in that sense, TOA data on its own could be useful—not for mapping land, but for understanding what’s happening above it."
  },
  {
    "objectID": "chapter_3.html#references",
    "href": "chapter_3.html#references",
    "title": "4  Remote sensing data",
    "section": "4.4 References",
    "text": "4.4 References\nLauri, 2019. NDVI(BOA) vs. NDVI(TOA) [WWW Document]. Terramonitor Feed. URL https://feed.terramonitor.com/ndvi-boa-ndvi-toa/ (accessed 3.28.25).\nNazeer, M., Ilori, C.O., Bilal, M., Nichol, J.E., Wu, W., Qiu, Z., Gayene, B.K., 2021. Evaluation of atmospheric correction methods for low to high resolutions satellite remote sensing data. Atmospheric Res. 249, 105308. https://doi.org/10.1016/j.atmosres.2020.105308"
  },
  {
    "objectID": "chapter_4.html#summary",
    "href": "chapter_4.html#summary",
    "title": "5  Galamsey",
    "section": "5.1 Summary",
    "text": "5.1 Summary\n\n5.1.1 Introduction\nThe system in Ghana is a unique system where policies are mainly created by the central government. The implementation of the policy is normally through the ministries. They mostly create taskforce and together with the police, enforce it.\n\n\n5.1.2 Background\nFor this week, I want to look at the illegal mining commonly known as Galamsey - (term is locally created from the phrase “gather and sell” - “Galamsey”). Ghana currently battling illegal mining being a mineral rich country. These minerals especially gold contributes a major part of the nation’s GDP. This reflects in Ghana being the 6th producer of Gold in 2024. The issue comes at a time where the prices of gold are at an all-time high. (Savage et al., 2025) This is shown in the graph below.\n\n\n\nFig. 1 Statistics on Gold production (Savage et al., 2025)\n\n\nEven though there are policies regulating mining activities, the country faces the impacts of galamsey. This is evident in the Ghana water company\n\n\n5.1.3 Policy\nIn Ghana, the Minerals and Mining Act 703 addresses small-scale mining specifically in sections 82 to 99. A license granted by the Minister for Mines or an authorized officer is required for engaging in small-scale mining (Onditi, 2022). To qualify, an applicant must be a Ghanaian citizen at least eighteen years old and registered by the Commission.\nThe Minister may designate areas for small-scale mining in the Gazette (Onditi, 2022). District Offices of the Commission compile a register of miners, supervise operations, provide training, and facilitate the formation of Small Scale Miners Associations (Onditi, 2022). Small Scale Mining Committees in designated areas assist the District Office in monitoring and promoting mining operations. Licensees must employ effective mining methods, observe safety rules, and protect the environment.\n\n\n5.1.4 Insights\nThe policy does state how ministry and their district offices monitor the illegal mining. However, the rise in illegal activities and destruction of water bodies and land shows a gap of ineffectiveness. There are some other parties involved in monitoring the mining activities such as Environmental Protection Agency (EPA) (Kazapoe et al., 2023).\nThe government established an anti-galamsey task force code named Operation Halt was formed to crackdown on illegal mining activities.(“Anti-galamsey task force destroys 10 Changfans other mining equipment on Pra River,” 2024) Even though the taskforce was formed in October 2024, the illegal mining still persist with four civil society organizations calling for leadership changes.(“Anti-galamsey task force destroys 10 Changfans other mining equipment on Pra River,” 2024; “Illegal mining menace,” 2025)"
  },
  {
    "objectID": "chapter_4.html#application",
    "href": "chapter_4.html#application",
    "title": "5  Galamsey",
    "section": "5.2 Application",
    "text": "5.2 Application\nWhile the exact method the anti-galamsey taskforce uses to identify illegal mining sites is unclear, Earth Observation (EO) could support smarter, evidence-based deployment. Drawing from relevant literature, I propose a data-driven approach using remote sensing tools.\n\n5.2.1 Paper 1: Water Quality Monitoring\nNiroumand-Jadidi, et al. (2020) assessed PRISMA hyperspectral imagery for retrieving water quality parameters, comparing it with Sentinel-2. PRISMA’s more spectral bands as compare to Sentinel-2. This is shown in figure 2. This was used with the WASI (Water Colour Simulator) model to detect suspended materials. Since illegal mining is closely linked with river pollution, this makes PRISMA a powerful tool for identifying active mining areas.(Kazapoe et al., 2023).\n\n\n\nFig. 2 PRISMA and Sentinel-2 Band Comparison (Niroumand-Jadidi et al., 2020)\n\n\nWater contamination often reflects mining activity—thus tracking turbidity, sediment, and color changes can help pinpoint illegal operations. Ghana’s water bodies are regularly affected, and the PRISMA sensor’s hyperspectral capacity makes it suitable for detecting subtle environmental changes missed by standard multispectral sensors.\n\n\n\nFig. 3 Illegal mining near a river (Ngom et al., 2023)\n\n\n\n\n5.2.2 Paper 2 Wider Mining Impacts\nNgom et al. (2023) explored EO methods to monitor artisanal mining impacts like soil degradation, deforestation, and turbidity. Their framework illustrates how different indicators(e.g. water properties) can support policy enforcement through remote sensing. I will adopt their workflow to help the mining policy in Ghana.\n\n\n5.2.3 Proposed Workflow\nBuilding on both papers, I propose a monitoring dashboard using data from Sentinel-2 (temporal coverage) and PRISMA (detailed sensing). EO data would be processed to flag suspicious changes in land use or water quality. These would be cross-referenced by partners like the Ghana Water Company and Forestry Commission, providing ground validation. Figure 4 shows the workflow.\n\n\n\nFig. 4 Dashboard workflow (Ngom et al., 2023)\n\n\nA refined dashboard would prioritize locations by impact, helping the taskforce deploy more strategically. This transparency could deter offenders, support early intervention, and reduce costs associated with water treatment and ecosystem restoration.\nUltimately, this system aligns with Ghana’s sustainable mining goals, protects agricultural land and water bodies, and supports SDGs 2, 6, 14, and 15."
  },
  {
    "objectID": "chapter_4.html#reflections",
    "href": "chapter_4.html#reflections",
    "title": "5  Galamsey",
    "section": "5.3 Reflections",
    "text": "5.3 Reflections\nIllegal mining does not just affect ecosystems,it directly impacts towns and people. In Ghana, water pollution from galamsey operations have led to reduced water production by the Ghana Water Company. They stated the level of pollution is to high for they machines to treats hence closing some of the water treatment plants. Residents are also exposed to heavy metals and contaminated water, which can lead to long-term health issues.\nWhat stands out is how Earth Observation (EO) could bridge the gap between policy and efficiency in policy enforcement. If implemented well, EO could help shift the response from reactive to proactive, targeting illegal operations before they cause irreversible damage.\nThe use of EO would also promote transparency—a key issue in Ghana’s mining governance. A public dashboard could build trust between citizens and government, showing that enforcement is data-driven and fair.\nFinally, there’s potential for EO to empower local agencies and communities. With proper training, district assemblies could use satellite data to guide land use decisions and involve local people in environmental protection.\nThis week showed me that remote sensing is not just about pixels and sensors—it’s a tool for environmental justice, urban resilience, and smarter governance."
  },
  {
    "objectID": "chapter_4.html#references",
    "href": "chapter_4.html#references",
    "title": "5  Galamsey",
    "section": "5.4 References",
    "text": "5.4 References\nAnti-galamsey task force destroys 10 Changfans other mining equipment on Pra River, 2024. URL https://citinewsroom.com/2024/10/operation-halt-anti-galamsey-task-force-destroys-mining-equipment-on-river-pra/ (accessed 3.10.25).\nEssah, M., 2022. Gold mining in Ghana and the UN Sustainable Development Goals: Exploring community perspectives on social and environmental injustices. Sustain. Dev. 30, 127–138. https://doi.org/10.1002/sd.2233\nIllegal mining menace: Sack Minerals Commission boss – CSOs to Mahama, 2025. . GhanaWeb. URL https://www.ghanaweb.com/GhanaHomePage/NewsArchive/(accessed (3.10.25).\nKazapoe, R.W., Amuah, E.E.Y., Abdiwali, S.A., Dankwa, P., Nang, D.B., Kazapoe, J.P., Kpiebaya, P., 2023. Relationship between small-scale gold mining activities and water use in Ghana: A review of policy documents aimed at protecting water bodies in mining communities. Environ. Chall. 12, 100727. https://doi.org/10.1016/j.envc.2023.100727\nNgom, N.M., Baratoux, D., Bolay, M., Dessertine, A., Abass Saley, A., Baratoux, L., Mbaye, M., Faye, G., Yao, A.K., Kouamé, K.J., 2023. Artisanal Exploitation of Mineral Resources: Remote Sensing Observations of Environmental Consequences, Social and Ethical Aspects. Surv. Geophys. 44, 225–247. https://doi.org/10.1007/s10712-022-09740-1\nNiroumand-Jadidi, M., Bovolo, F., Bruzzone, L., 2020. Water Quality Retrieval from PRISMA Hyperspectral Images: First Experience in a Turbid Lake and Comparison with Sentinel-2. Remote Sens. 12, 3984. https://doi.org/10.3390/rs12233984\nSavage, S., Conboye, J., Fray, K., Adeoye, A., Bhandari, A., 2025. How illegal gold mining is fuelling a chocolate shortage. Financ. Times.\nOnditi, F., 2022. Introduction: A Study of Inequalities, Resource Conflict, and Sustainability, in: Onditi, F. (Ed.), Gender Inequalities in Africa’s Mining Policies: A Study of Inequalities, Resource Conflict and Sustainability. Springer, Singapore, pp. 1–27. https://doi.org/10.1007/978-981-16-8252-0_1"
  },
  {
    "objectID": "chapter_5.html#summary",
    "href": "chapter_5.html#summary",
    "title": "6  Google Earth Engine",
    "section": "6.1 Summary",
    "text": "6.1 Summary\nThis week was all about Google Earth Engine (GEE). It’s a powerful cloud-based platform that lets you analyse satellite data without downloading huge files. Instead of running things on your laptop, GEE does the heavy lifting for you online. We looked at how it makes working with remote sensing data easier, faster, and more accessible — especially for global-scale work.\nWhat really stood out for me was the shift from traditional desktop processing to cloud-based analysis. Before, you’d have to download loads of satellite data, clean it up, and then run it on your own machine — which takes forever and kills your laptop. But with GEE, the data’s already online, and the processing happens in the cloud. This means it runs faster and doesn’t depend on your computer’s power. I think this is a big deal, especially for people in places like Ghana where access to powerful machines can be limited. GEE basically opens the door for more people to do meaningful analysis, even on large datasets, without needing fancy tech setups. That feels like a huge game changer."
  },
  {
    "objectID": "chapter_5.html#application",
    "href": "chapter_5.html#application",
    "title": "6  Google Earth Engine",
    "section": "6.2 Application",
    "text": "6.2 Application\nTo understand how GEE works in practice, I looked at two studies that used it for land cover classification and change detection — both with practical use in urban planning and sustainability.\nThe first paper by Kamal et al. (2019) focused on monitoring land cover change in Dhaka, Bangladesh, from 1990 to 2017. They used Landsat imagery and ran a Random Forest classification through GEE. Everything from data access to processing was done in the cloud. That meant no downloading, no storage stress — just quick, consistent analysis over nearly three decades. Their output showed a massive shift from agricultural and forest areas to urban land. It was a good example of how GEE can scale analysis across time without complex infrastructure.\nThe second study by Jin et al. (2019) took things a step further. They built a 30-meter global land cover map using over 1 million Landsat images — all processed within GEE. They used supervised classification and trained their model using samples collected from multiple sources. What stood out was how GEE let them handle such a large dataset with relative ease. The platform allowed for global-scale mapping, which would’ve been nearly impossible using local machines.\nBoth studies showed how GEE makes remote sensing more accessible, especially for researchers and policymakers in the Global South. It reduces technical barriers and speeds up workflows without sacrificing accuracy. I can definitely see how this could be used for urban planning in Ghana — tracking informal settlements, land-use conflicts, or even flood zones over time."
  },
  {
    "objectID": "chapter_5.html#reflection",
    "href": "chapter_5.html#reflection",
    "title": "6  Google Earth Engine",
    "section": "6.3 Reflection",
    "text": "6.3 Reflection\nHonestly, I really like the idea behind Google Earth Engine. It removes a lot of the barriers that come with remote sensing — like needing a high-spec laptop or dealing with slow downloads. Everything’s just there and ready to use. I can definitely see how this could be super useful in Ghana, especially for government agencies or local researchers who may not have access to powerful machines but still want to monitor things like illegal mining, urban sprawl, or deforestation.\nWhat surprised me was how quick the results came through. With just a bit of JavaScript, you can visualise changes over time or run NDVI analysis in seconds. I’m still getting used to the coding part, but it feels way more approachable than I expected.\nOne thing I’m still wondering about, though, is what happens when internet access isn’t stable. Like, would this be fully reliable in rural areas where connections drop often? And also, what’s the long-term sustainability of using a free cloud service run by a private company? Those are things I’d want to look into more.\nBut overall, this week made me feel like big, global-scale analysis is no longer just for people with big funding or expensive hardware. That’s a win."
  },
  {
    "objectID": "chapter_6.html#summary",
    "href": "chapter_6.html#summary",
    "title": "7  Classification I",
    "section": "7.1 Summary",
    "text": "7.1 Summary\nThis week was about classification, which basically is turning raw satellite imagery into something meaningful. Thus, instead of looking at raw images, classification lets us extract useful information by categorizing them into different classes like urban, vegetation, water, etc. This is done by using machine learning algorithms like Support Vector Machines (SVM) or Random Forest to analysis the pixel values and assign them to different classes.\nAn example is the use of Landsat data to map urban growth. Taking the case of Iskandar, Malaysia (Figure 1), Landsat imagery was classified to show land cover types—like urban built-up areas, vegetation, and waterbodies (Yasin et al., 2022).\n\n\n\nFig 1. Landsat classified data on Iskandar Malaysia region (Yasin et al., 2022)\n\n\nClassification can be practically useful in monitoring city growth of time to uncover trends and use it for future planning.\n\n7.1.1 Choosing the Right Sensor\nThe type of sensor used makes a big difference in how accurate your classification turns out. For instance, hyperspectral sensors can capture really fine details—perfect for plants species mapping or vegetation health. But for general land cover, a multispectral sensor like Landsat or Sentinel-2 might be enough. This is just like selecting a satellite based on the bands. Figure 2 shows highlights sensors to objectives.\n\n\n\nFig 2. Mapping sensors to objectives. (Shahtahmassebi et al., 2020)\n\n\n\n\n7.1.2 Classification Methods & SVM\nThere are two basic types of classification methods:\n\nClassification trees – for categories like land cover\nRegression trees – for continuous data like temperature\n\nBut both can suffer from overfitting—where the model works too well on the training data but fails on new input. To avoid this, Support Vector Machines (SVM) are adopted used.\nSVM is a supervised machine learning model that finds the best boundary (called a hyperplane) between two classes—like urban and vegetation (see Figure 3). It’s great for high-dimensional data like hyperspectral imagery. It uses kernel functions (like RBF or polynomial) and parameters like C and gamma to tune the model (Mountrakis et al., 2011).\n\n\n\nFig 3. SVM Hyperplane boundary (Mountrakis et al., 2011)\n\n\nSVMs perform well with small datasets and generalize better than decision trees and neural networks, though they’re slower with big data—where Random Forest or deep learning might be more practical.\nI will personally mostly use SVM for my classification tasks. Then use a Classification trees or Regression trees as a validation check and also figure out if my data is too big for SVM."
  },
  {
    "objectID": "chapter_6.html#application",
    "href": "chapter_6.html#application",
    "title": "7  Classification I",
    "section": "7.2 Application",
    "text": "7.2 Application\nSupport Vector Machines (SVM) have been widely applied in classification tasks. I will refer to two studies that used SVM in the context of urban analysis.\nThe first study, by Zylshal et al. (2016), focused on identifying urban green spaces in Jakarta using high-resolution Pleiades-1A imagery. The classification process involved defining land cover classes—vegetation, non-vegetation, and water—followed by training the SVM model with a small dataset. Since SVM is a binary classifier, a “one-against-one” strategy was used to classify each pair of land cover types. Although the study did not state the exact input features, the data processing flowchart (figure 4) shows NDVI, NDWI and MSAVI used likely as input features, given their relevance in vegetation analysis.\n\n\n\nFig 4. Data processing flowchart (Zylshal et al., 2016)\n\n\nInstead of classifying individual pixels, the study used multiresolution segmentation to group pixels into meaningful objects before applying classification. The output was further refined using expert rules and validated through an accuracy assessment, achieving 86% accuracy. This study effectively demonstrated the integration of SVM with Object-Based Image Analysis (OBIA) for high-resolution classification.\nThe second study, by Karimi et al. (2019), applied SVM to predict urban expansion in Guilford County, North Carolina, using data from the National Land Cover Database (USGS) and other supporting datasets. Unlike the first study’s spatial classification, this focused on temporal prediction, modeling the transition from “unbuilt” to “built” land as shown in figure 5.\n\n\n\nFig 5. Binary classification of simulated LULC map in 2016 (Karimi et al., 2019)\n\n\nTo improve results, the model was tuned through kernel selection and parameter optimization. Because urban growth datasets are often imbalanced, with more unbuilt than built land, the study used strategic sampling to reduce bias. It achieved 78% accuracy, slightly lower than the first study, likely due to the larger dataset and the complexity of time-based prediction. SVM proved valuable in handling both continuous and categorical variables, making it well-suited for modeling urban growth trends.\n\n7.2.1 Insights for applications\nBoth studies applied SVM as a binary classifier, but their approaches differed. One focused on spatial classification, while the other tackled temporal change prediction. The second study likely dealt with a larger dataset, which might explain its lower accuracy, as SVM tends to perform better on smaller datasets. This raises the question of how well SVM scales for large-scale urban studies. A possible improvement would be enhancing SVM models with other machine learning techniques to handle large datasets more efficiently."
  },
  {
    "objectID": "chapter_6.html#reflections",
    "href": "chapter_6.html#reflections",
    "title": "7  Classification I",
    "section": "7.3 Reflections",
    "text": "7.3 Reflections\nThis week deepened my understanding of how Support Vector Machines (SVM) are applied in urban classification tasks. Looking at both studies helped me see the flexibility—but also the limits—of the model.\nIn the first study by Zylshal et al. (2016), the use of high-resolution imagery and indices like NDVI, NDWI, and MSAVI made sense for mapping urban green spaces in Jakarta. What stood out was the use of multiresolution segmentation—grouping pixels into meaningful objects before applying SVM. That, along with expert-based refinement, led to 86% accuracy, showing how SVM paired with Object-Based Image Analysis (OBIA) can be powerful in detailed, small-scale studies.\nIn contrast, the second study by Karimi et al. (2019) focused on predicting urban expansion over time in North Carolina. It used broader datasets and aimed to model how “unbuilt” land becomes “built.” The team fine-tuned the model and applied strategic sampling to handle imbalanced classes—common in urban growth studies. While it achieved 78% accuracy, the lower performance reflects the challenges of using SVM on larger, more complex datasets.\nWhat I found interesting is that both studies relied on SVM as a binary classifier, yet their outcomes varied based on scale, data volume, and focus—spatial vs. temporal. This raised an important question: how scalable is SVM for large-scale urban analysis?\nSVM works well with limited, high-quality data, but in broader applications like national urban expansion studies, it might struggle with processing speed and generalization. A key takeaway is that SVM could be enhanced by hybrid approaches, for instance, integrating it with Random Forest, neural networks, or rule-based methods for better scalability.\nOverall, this week showed me that classification is not just a technical process—it’s about tailoring tools to fit data types, goals, and scale, and SVM is just one part of a growing toolbox in urban remote sensing."
  },
  {
    "objectID": "chapter_6.html#references",
    "href": "chapter_6.html#references",
    "title": "7  Classification I",
    "section": "7.4 References",
    "text": "7.4 References\nKarimi, F., Sultana, S., Shirzadi Babakan, A., Suthaharan, S., 2019. An enhanced support vector machine model for urban expansion prediction. Comput. Environ. Urban Syst. 75, 61–75. https://doi.org/10.1016/j.compenvurbsys.2019.01.001 Mountrakis, G., Im, J., Ogole, C., 2011. Support vector machines in remote sensing: A review. ISPRS J. Photogramm. Remote Sens. 66, 247–259. https://doi.org/10.1016/j.isprsjprs.2010.11.001 Shahtahmassebi, A., Li, C., Yifan, F., Wu, Y., Lin, Y., Gan, M., Wang, K., Malik, A., Blackburn, A., 2020. Remote sensing of urban green spaces: A review. Urban For. Urban Green. 57, 126946. https://doi.org/10.1016/j.ufug.2020.126946 Yasin, M.Y., Abdullah, J., Noor, Norzailawati Mohd, Yusoff, M.M., Noor, Nisfariza Mohd, 2022. Landsat observation of urban growth and land use change using NDVI and NDBI analysis. IOP Conf. Ser. Earth Environ. Sci. 1067, 012037. https://doi.org/10.1088/1755-1315/1067/1/012037 Yu, W., Liu, T., Valdez, R., Gwinn, M., Khoury, M.J., 2010. Application of support vector machine modeling for prediction of common diseases: the case of diabetes and pre-diabetes. BMC Med. Inform. Decis. Mak. 10, 16. https://doi.org/10.1186/1472-6947-10-16 Zylshal, Sulma, S., Yulianto, F., Nugroho, J.T., Sofan, P., 2016a. A support vector machine object based image analysis approach on urban green space extraction using"
  },
  {
    "objectID": "chapter_7.html#summary",
    "href": "chapter_7.html#summary",
    "title": "8  Classification II",
    "section": "8.1 Summary",
    "text": "8.1 Summary\nThis week built on last week’s classification session, but took a different turn by focusing on pre-classified datasets and sub-pixel analysis. Instead of starting from raw satellite imagery, we explored ready-to-use classification products like GlobeLand30, MODIS, and Dynamic World. These datasets allow us to work faster but raise questions about the loss of control over classification accuracy and assumptions baked into the processing.\nThe key focus for me was sub-pixel classification—a method that tries to identify multiple land cover types within a single pixel. This is really helpful when working with coarse resolution imagery where, for example, a 30m pixel might contain buildings, roads, and trees. Traditional classification would assign it one label, but sub-pixel methods estimate the proportions of each type instead.\n\n\n\nFig. 1 A zoomed-in pixel showing buildings, vegetation, and roads (MacLachlan et al., 2017)\n\n\nSub-pixel analysis is especially useful in urban fringe areas, where land cover is complex and mixed. But it also raises new challenges around validation and reliability. That leads us into the importance of accuracy assessment.\n\n8.1.1 Accuracy Assessment\nIn remote sensing, three key metrics help evaluate performance:\nProducer Accuracy – How well the model captures a class based on reference data \nUser Accuracy – How likely the modelled class is correct when visited on the ground\nOverall Accuracy – The total correct classifications across all classes \n\n\n\nFig. 2 Confusion matrix from Dynamic World (Brown et al., 2022)\n\n\nLooking at Dynamic World, for instance, the model achieved 94% recall for water; meaning it detected most water pixels—but only 87% user accuracy; meaning some areas it labelled as water were not actually water on the ground. Averaging across all classes, the overall accuracy came to around 72%, which reflects the trade-off between global coverage and accuracy.\nThere is another metric called the Kappa coefficient, which accounts for the agreement between the model and random chance. It’s a more robust measure than overall accuracy, especially when classes are imbalanced."
  },
  {
    "objectID": "chapter_7.html#applications",
    "href": "chapter_7.html#applications",
    "title": "8  Classification II",
    "section": "8.2 Applications",
    "text": "8.2 Applications\nFor this week, I focus what methods they use for their sub pixel classification and how they validate their results. And reflect on trade-off between accuracy and coverage.\nThe first study is by Suresh & Jain (2018) explored subpixel classification on a small urban scale using high resolution QuickBird imagery (0.6m). They adopted two main methods, colorimetry and chromaticity diagrams.They used colorimetry, specifically the CIE-XYZ colour space, to model how colours within a pixel mix, estimating the proportions of different land cover types. Then, comparing chromatic distances between neighbouring pixels, they broke down mixed pixels more accurately. They validated their method using a Fuzzy Error Matrix, which showed better results than standard soft classifiers. This is shown the table below.\n\n\n\nTable. 1 Accuracy outputs comparing authors proposed and conventional approach (Suresh and Jain, 2018)\n\n\nInsights\nThis is a unique method because it doesn’t rely om just spectral band but rather looks at how colours mix inside a pixel. I am wondering method might be bias when it has pixels with in low surfaces reflectance (water bodies) or surfaces with very similar colours. With high resolution sensor, I understand why it was utilized to classify urban cities on a small scale but I am not sure how well it would hold up across a larger area with many variation of colours.\nAlso, I am curious on how it deals with shadows. Assessment test showed the method had a high accuracy in a urban setting, meaning the was able to classify even with the high presence of shadows. I think they try the method on a larger scale to see how well it performs as well."
  },
  {
    "objectID": "chapter_7.html#reflection",
    "href": "chapter_7.html#reflection",
    "title": "8  Classification II",
    "section": "8.3 Reflection",
    "text": "8.3 Reflection\nThis week is last but one week with an entry for the learning diary. I haven’t had the chance to dive deeply into all the methods and models introduced in class, but I’ve come to realise that delving into a method in depth helps build real proficiency. That said, there’s a trade-off focusing deeply on a few methods can mean having only a surface level understanding of others. I think my approach is to understand the purpose of each method and its limitations. This way, I can decide when a method is appropriate and even explore how to combine these methods for better results. This week, I chose a paper that introduced a method we hadn’t covered in class, just to broaden my scope. The idea of classifying a pixel based on how colours mix within it was fascinating. It’s a different angle from the typical spectral-band-driven approaches.\nThis week, I chose a paper that introduced a method we hadn’t covered in class, just to broaden my scope. The idea of classifying a pixel based on how colours mix within it was fascinating. It’s a different angle from the typical spectral-band-driven approaches."
  },
  {
    "objectID": "chapter_7.html#reference",
    "href": "chapter_7.html#reference",
    "title": "8  Classification II",
    "section": "8.4 Reference",
    "text": "8.4 Reference\nBrown, C.F., Brumby, S.P., Guzder-Williams, B., Birch, T., Hyde, S.B., Mazzariello, J., Czerwinski, W., Pasquarella, V.J., Haertel, R., Ilyushchenko, S., Schwehr, K., Weisse, M., Stolle, F., Hanson, C., Guinan, O., Moore, R., Tait, A.M., 2022. Dynamic World, Near real-time global 10 m land use land cover mapping. Sci. Data 9, 251. https://doi.org/10.1038/s41597-022-01307-4\nMacLachlan, A., Roberts, G., Biggs, E., Boruff, B., 2017. Subpixel land-cover classification for improved urban area estimates using Landsat. Int. J. Remote Sens. 38, 5763–5792. https://doi.org/10.1080/01431161.2017.1346403\nSuresh, M., Jain, K., 2018. Subpixel level mapping of remotely sensed image using colorimetry. Egypt. J. Remote Sens. Space Sci. 21, 65–72. https://doi.org/10.1016/j.ejrs.2017.02.004"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "10  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  }
]